{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqzPLIjrrKvpO/55VGjnQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKgithub844/neuroga-attrition-predictor/blob/main/PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0BQQ49LhtIW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from random import randint, random\n",
        "import math\n",
        "\n",
        "# =============================================================================\n",
        "# Configuration Parameters\n",
        "# =============================================================================\n",
        "MAX_FEATURES = 12\n",
        "MIN_FEATURES = 8\n",
        "MAX_LAYERS = 3\n",
        "MIN_LAYERS = 1\n",
        "MAX_NEURONS = 9\n",
        "MIN_NEURONS = 5\n",
        "\n",
        "GEN_COUNT = 3\n",
        "POP_SIZE = 25\n",
        "ELITE_COUNT = math.ceil(POP_SIZE * 0.1)\n",
        "MUTATION_PROB = 0.01\n",
        "TARGET_SCORE = 1.01\n",
        "TOURNAMENT_SIZE = math.ceil(POP_SIZE * 0.2)\n",
        "\n",
        "DATA_PATH = \"dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
        "TARGET_COL = \"Attrition\"\n",
        "OHE_COLUMNS = [\"BusinessTravel\", \"Department\", \"EducationField\", \"JobRole\", \"MaritalStatus\"]\n",
        "BINARY_COLUMNS = [\"Gender\", \"OverTime\", \"Over18\"]\n",
        "DROP_COLUMNS = [\"EmployeeNumber\", \"EmployeeCount\", \"Over18\", \"DailyRate\", \"HourlyRate\", \"MonthlyRate\", \"StandardHours\"]\n",
        "SCALE_EXCLUDE = OHE_COLUMNS + BINARY_COLUMNS + [\"EmployeeNumber\", \"Attrition\", \"Education\", \"EnvironmentSatisfaction\", \"JobInvolvement\", \"JobLevel\", \"JobSatisfaction\", \"StockOptionLevel\", \"WorkLifeBalance\", \"RelationshipSatisfaction\"]\n",
        "\n",
        "# =============================================================================\n",
        "# Data Controller\n",
        "# =============================================================================\n",
        "class DataController:\n",
        "    __instance = None\n",
        "\n",
        "    @staticmethod\n",
        "    def shared():\n",
        "        if DataController.__instance is None:\n",
        "            DataController()\n",
        "        return DataController.__instance\n",
        "\n",
        "    def __init__(self):\n",
        "        if DataController.__instance is not None:\n",
        "            raise Exception(\"DataController is a singleton!\")\n",
        "        DataController.__instance = self\n",
        "\n",
        "    def read(self, path):\n",
        "        self.df = pd.read_csv(path)\n",
        "\n",
        "    def preprocess(self):\n",
        "        self.df.drop(columns=DROP_COLUMNS, inplace=True)\n",
        "        for col in BINARY_COLUMNS:\n",
        "            if col in self.df:\n",
        "                self.df[col] = self.df[col].astype('category').cat.codes\n",
        "        self.df = pd.get_dummies(self.df, columns=OHE_COLUMNS)\n",
        "        to_scale = self.df.columns.difference(SCALE_EXCLUDE)\n",
        "        scaler = StandardScaler()\n",
        "        self.df[to_scale] = scaler.fit_transform(self.df[to_scale])\n",
        "\n",
        "    def split(self, target_col, test_fraction=0.2):\n",
        "        X = self.df.drop(columns=[target_col])\n",
        "        y = self.df[target_col].astype('category').cat.codes\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_fraction, random_state=0)\n",
        "\n",
        "    def get_train_X(self): return self.X_train\n",
        "    def get_train_y(self): return self.y_train\n",
        "    def get_feature_count(self): return len(self.X_train.columns)\n",
        "\n",
        "# =============================================================================\n",
        "# FeatureMask and ModelShape\n",
        "# =============================================================================\n",
        "class FeatureMask:\n",
        "    def __init__(self, mask):\n",
        "        self.mask = mask\n",
        "\n",
        "    def mutate(self, rate):\n",
        "        self.mask = [1 - bit if random() < rate else bit for bit in self.mask]\n",
        "\n",
        "    def cross_with(self, partner):\n",
        "        idx = randint(0, len(self.mask) - 1)\n",
        "        return (\n",
        "            self.mask[:idx+1] + partner.mask[idx+1:],\n",
        "            partner.mask[:idx+1] + self.mask[idx+1:]\n",
        "        )\n",
        "\n",
        "    def raw(self): return self.mask\n",
        "\n",
        "class ModelShape:\n",
        "    def __init__(self, shape):\n",
        "        self.shape = shape\n",
        "\n",
        "    def mutate(self, rate):\n",
        "        if random() < rate:\n",
        "            for i in range(len(self.shape)):\n",
        "                self.shape[i] = randint(MIN_NEURONS, MAX_NEURONS)\n",
        "\n",
        "    def cross_with(self, partner):\n",
        "        idx = randint(0, min(len(self.shape), len(partner.shape)) - 1)\n",
        "        return (\n",
        "            self.shape[:idx+1] + partner.shape[idx+1:],\n",
        "            partner.shape[:idx+1] + self.shape[idx+1:]\n",
        "        )\n",
        "\n",
        "    def raw(self): return self.shape\n",
        "\n",
        "# =============================================================================\n",
        "# NeuroGA (Neural Network individual)\n",
        "# =============================================================================\n",
        "class NeuroGA(MLPClassifier):\n",
        "    def __init__(self, feat_mask=None, shape=None):\n",
        "        dc = DataController.shared()\n",
        "        mask = feat_mask if feat_mask else [1] * dc.get_feature_count()\n",
        "        arch = shape if shape else [randint(MIN_NEURONS, MAX_NEURONS) for _ in range(randint(MIN_LAYERS, MAX_LAYERS))]\n",
        "        self.feat_mask = FeatureMask(mask)\n",
        "        self.shape = ModelShape(arch)\n",
        "        self.fitness = 0.0\n",
        "        super().__init__(hidden_layer_sizes=tuple(arch), max_iter=3000, learning_rate_init=0.001, random_state=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def create(): return NeuroGA()\n",
        "\n",
        "    def filter_X(self, X):\n",
        "        drop = [i for i, bit in enumerate(self.feat_mask.raw()) if bit == 0]\n",
        "        return X.drop(X.columns[drop], axis=1)\n",
        "\n",
        "    def evaluate_accuracy(self, X, y):\n",
        "        filtered_X = self.filter_X(X)\n",
        "        kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "        scores = []\n",
        "        for train_idx, test_idx in kf.split(filtered_X):\n",
        "            self.fit(filtered_X.iloc[train_idx], y.iloc[train_idx])\n",
        "            scores.append(self.score(filtered_X.iloc[test_idx], y.iloc[test_idx]))\n",
        "        self.fitness = np.mean(scores)\n",
        "\n",
        "    def cross_with(self, other):\n",
        "        f1, f2 = self.feat_mask.cross_with(other.feat_mask)\n",
        "        s1, s2 = self.shape.cross_with(other.shape)\n",
        "        return NeuroGA(f1, s1), NeuroGA(f2, s2)\n",
        "\n",
        "    def apply_mutation(self, rate):\n",
        "        self.feat_mask.mutate(rate)\n",
        "        self.shape.mutate(rate)\n",
        "\n",
        "    def get_score(self): return self.fitness\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Features: {self.feat_mask.raw()}, Shape: {self.shape.raw()}, Accuracy: {self.fitness:.4f}\"\n",
        "\n",
        "# =============================================================================\n",
        "# ModelPool and Evolver\n",
        "# =============================================================================\n",
        "class ModelPool:\n",
        "    def __init__(self):\n",
        "        self.members = []\n",
        "\n",
        "    def add(self, member):\n",
        "        self.members.append(member)\n",
        "        self.members.sort(key=lambda m: m.get_score(), reverse=True)\n",
        "\n",
        "    def size(self): return len(self.members)\n",
        "    def top(self): return self.members[0]\n",
        "    def all(self): return self.members\n",
        "\n",
        "    def evaluate_fitness(self, X, y):\n",
        "        for m in self.members:\n",
        "            m.evaluate_accuracy(X, y)\n",
        "\n",
        "    @staticmethod\n",
        "    def init(factory):\n",
        "        pool = ModelPool()\n",
        "        while pool.size() < POP_SIZE:\n",
        "            pool.add(factory())\n",
        "        return pool\n",
        "\n",
        "class Evolver:\n",
        "    @staticmethod\n",
        "    def evolve(current):\n",
        "        new_pool = ModelPool()\n",
        "        elites = current.all()[:ELITE_COUNT]\n",
        "        for elite in elites:\n",
        "            new_pool.add(elite)\n",
        "        while new_pool.size() < POP_SIZE:\n",
        "            p1 = Evolver.select(current)\n",
        "            p2 = Evolver.select(current)\n",
        "            c1, c2 = p1.cross_with(p2)\n",
        "            new_pool.add(c1)\n",
        "            if new_pool.size() < POP_SIZE:\n",
        "                new_pool.add(c2)\n",
        "        for i in range(ELITE_COUNT, POP_SIZE):\n",
        "            new_pool.all()[i].apply_mutation(MUTATION_PROB)\n",
        "        return new_pool\n",
        "\n",
        "    @staticmethod\n",
        "    def select(pool):\n",
        "        return max([pool.all()[randint(0, POP_SIZE - 1)] for _ in range(TOURNAMENT_SIZE)], key=lambda m: m.get_score())\n",
        "\n",
        "# =============================================================================\n",
        "# Execution Pipeline\n",
        "# =============================================================================\n",
        "def prepare_data():\n",
        "    dc = DataController.shared()\n",
        "    dc.read(DATA_PATH)\n",
        "    dc.preprocess()\n",
        "    dc.split(TARGET_COL)\n",
        "    print(\"Training features:\", dc.get_train_X().columns.tolist())\n",
        "    return dc\n",
        "\n",
        "def initialize_population():\n",
        "    dc = DataController.shared()\n",
        "    pool = ModelPool.init(NeuroGA.create)\n",
        "    pool.evaluate_fitness(dc.get_train_X(), dc.get_train_y())\n",
        "    print_generation(pool, 0)\n",
        "    return pool\n",
        "\n",
        "def print_generation(pool, gen):\n",
        "    print(f\"Generation #{gen} | Top Accuracy: {pool.top().get_score():.4f}\")\n",
        "    for i, member in enumerate(pool.all()):\n",
        "        print(f\"Model {i:02d}: {member}\")\n",
        "\n",
        "def main():\n",
        "    prepare_data()\n",
        "    dc = DataController.shared()\n",
        "    population = initialize_population()\n",
        "    generation = 1\n",
        "    while generation < GEN_COUNT and population.top().get_score() < TARGET_SCORE:\n",
        "        population = Evolver.evolve(population)\n",
        "        population.evaluate_fitness(dc.get_train_X(), dc.get_train_y())\n",
        "        print_generation(population, generation)\n",
        "        generation += 1\n",
        "    print(\"\\nBest Evolved Neural Network:\")\n",
        "    print(population.top())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}